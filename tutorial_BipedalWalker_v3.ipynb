{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "view-in-github"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/ElegantRL/blob/master/tutorial_BipedalWalker_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "c1gUG3OCJ5GS"
            },
            "source": [
                "# **BipedalWalker-v3 Example in ElegantRL**\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "FGXyBBvL0dR2"
            },
            "source": [
                "# **Task Description**\n",
                "\n",
                "[BipedalWalker-v3](https://gym.openai.com/envs/BipedalWalker-v2/) is a robotic task in OpenAI Gym since it performs one of the most fundamental skills: moving. In this task, our goal is to get a 2D bipedal walker to walk through rough terrain. BipedalWalker is a difficult task in continuous action space, and there are only a few RL implementations can reach the target reward."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "DbamGVHC3AeW"
            },
            "source": [
                "# **Part 1: Install ElegantRL**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "U35bhkUqOqbS",
                "outputId": "79ace170-9a20-46cd-db96-957fd42a472f"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting git+https://github.com/AI4Finance-LLC/ElegantRL.git\n",
                        "  Cloning https://github.com/AI4Finance-LLC/ElegantRL.git to /private/var/folders/36/bvf53yyd46b4pd8vg8rtv5fc0000gn/T/pip-req-build-zpomu1zd\n",
                        "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-LLC/ElegantRL.git /private/var/folders/36/bvf53yyd46b4pd8vg8rtv5fc0000gn/T/pip-req-build-zpomu1zd\n",
                        "^C\n",
                        "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
                        "\u001b[0m"
                    ]
                }
            ],
            "source": [
                "# install elegantrl library\n",
                "!pip install git+https://github.com/AI4Finance-LLC/ElegantRL.git"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "UVdmpnK_3Zcn"
            },
            "source": [
                "# **Part 2: Import Packages**\n",
                "\n",
                "\n",
                "*   **elegantrl**\n",
                "*   **OpenAI Gym**: a toolkit for developing and comparing reinforcement learning algorithms.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "id": "AAPdjovQrTpE"
            },
            "outputs": [],
            "source": [
                "import gym\n",
                "from elegantrl.agents import AgentPPO\n",
                "from elegantrl.train.config import get_gym_env_args, Arguments\n",
                "from elegantrl.train.run import *\n",
                "\n",
                "gym.logger.set_level(40) # Block warning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "z2Ik5cDoyPGU"
            },
            "source": [
                "# **Part 3: Get environment information**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "wwkZXiHtyV6f",
                "outputId": "880d25f5-d1f0-4cd2-8f78-bb5409330101"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING: env.action_space.high [1. 1. 1. 1.]\n",
                        "env_args = {\n",
                        "    'env_num': 1,\n",
                        "    'env_name': 'BipedalWalker-v3',\n",
                        "    'max_step': 1600,\n",
                        "    'state_dim': 24,\n",
                        "    'action_dim': 4,\n",
                        "    'if_discrete': False,\n",
                        "    'target_return': 300,\n",
                        "}\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'env_num': 1,\n",
                            " 'env_name': 'BipedalWalker-v3',\n",
                            " 'max_step': 1600,\n",
                            " 'state_dim': 24,\n",
                            " 'action_dim': 4,\n",
                            " 'if_discrete': False,\n",
                            " 'target_return': 300}"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_gym_env_args(gym.make(\"BipedalWalker-v3\"), if_print=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "3n8zcgcn14uq"
            },
            "source": [
                "# **Part 4: Specify Agent and Environment**\n",
                "\n",
                "*   **agent**: chooses a agent (DRL algorithm) from a set of agents in the [directory](https://github.com/AI4Finance-Foundation/ElegantRL/tree/master/elegantrl/agents).\n",
                "*   **env_func**: the function to create an environment, in this case, we use gym.make to create BipedalWalker-v3.\n",
                "*   **env_args**: the environment information.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {
                "id": "E03f6cTeajK4"
            },
            "outputs": [],
            "source": [
                "env_func = gym.make\n",
                "env_args = {\n",
                "    \"env_num\": 1,\n",
                "    \"env_name\": \"BipedalWalker-v3\",\n",
                "    \"max_step\": 1600,\n",
                "    \"state_dim\": 24,\n",
                "    \"action_dim\": 4,\n",
                "    \"if_discrete\": False,\n",
                "    \"target_return\": 300,\n",
                "    \"id\": \"BipedalWalker-v3\",\n",
                "}\n",
                "\n",
                "env = gym.make(\"BipedalWalker-v3\")\n",
                "args = Arguments(AgentPPO, env=env, env_func=env_func, env_args=env_args)\n",
                "\n",
                "# args = Arguments(AgentPPO, env_func=env_func, env_args=env_args)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rcFcUkwfzHLE"
            },
            "source": [
                "# **Part 4: Specify hyper-parameters**\n",
                "A list of hyper-parameters is available [here](https://elegantrl.readthedocs.io/en/latest/api/config.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {
                "id": "9WCAcmIfzGyE"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "6400\n"
                    ]
                }
            ],
            "source": [
                "args.target_step = args.max_step * 4\n",
                "args.gamma = 0.98\n",
                "args.eval_times = 2**4\n",
                "print(args.target_step)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "z1j5kLHF2dhJ"
            },
            "source": [
                "# **Part 5: Train and Evaluate the Agent**\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "KGOPSD6da23k",
                "outputId": "2a8ed03b-b306-45f8-c530-adf72438c5bd"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "| Arguments Remove cwd: ./BipedalWalker-v3_PPO_0\n",
                        "################################################################################\n",
                        "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not map",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/Users/jimmy/Projects/RL/ElegantRL/tutorial_BipedalWalker_v3.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jimmy/Projects/RL/ElegantRL/tutorial_BipedalWalker_v3.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_and_evaluate(args)\n",
                        "File \u001b[0;32m~/Projects/RL/ElegantRL/elegantrl/train/run.py:106\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    104\u001b[0m if_train \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mwhile\u001b[39;00m if_train:\n\u001b[0;32m--> 106\u001b[0m     trajectory \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mexplore_env(env, horizon_len)\n\u001b[1;32m    107\u001b[0m     steps, r_exp \u001b[39m=\u001b[39m buffer\u001b[39m.\u001b[39mupdate_buffer((trajectory,))\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m if_off_policy:\n",
                        "File \u001b[0;32m~/Projects/RL/ElegantRL/elegantrl/agents/AgentPPO.py:88\u001b[0m, in \u001b[0;36mAgentPPO.explore_one_env\u001b[0;34m(self, env, target_step, random_exploration)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m state\n\u001b[1;32m     87\u001b[0m last_done[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m step_i\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_trajectory(traj_list, last_done)\n",
                        "File \u001b[0;32m~/Projects/RL/ElegantRL/elegantrl/agents/AgentBase.py:288\u001b[0m, in \u001b[0;36mAgentBase.convert_trajectory\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m# assert len(buf_items[0]) == step\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m# assert len(buf_items[0][0]) == self.env_num\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39m'''stack items'''\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m traj_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(traj_list1[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    289\u001b[0m traj_action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(traj_list1[\u001b[39m3\u001b[39m])\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(traj_action\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
                        "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not map"
                    ]
                }
            ],
            "source": [
                "train_and_evaluate(args)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "JPXOxLSqh5cP"
            },
            "source": [
                "Understanding the above results::\n",
                "*   **Step**: the total training steps.\n",
                "*  **MaxR**: the maximum reward.\n",
                "*   **avgR**: the average of the rewards.\n",
                "*   **stdR**: the standard deviation of the rewards.\n",
                "*   **objA**: the objective function value of Actor Network (Policy Network).\n",
                "*   **objC**: the objective function value (Q-value)  of Critic Network (Value Network)."
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "include_colab_link": true,
            "name": "tutorial_BipedalWalker-v3.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.9.12",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.12"
        },
        "vscode": {
            "interpreter": {
                "hash": "93ba34249c17563af2bda868fdb6eca5c87de58ecf012fca691323eb0b85f674"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
