{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "view-in-github"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/ElegantRL/blob/master/tutorial_BipedalWalker_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "c1gUG3OCJ5GS"
            },
            "source": [
                "# **BipedalWalker-v3 Example in ElegantRL**\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "FGXyBBvL0dR2"
            },
            "source": [
                "# **Task Description**\n",
                "\n",
                "[BipedalWalker-v3](https://gym.openai.com/envs/BipedalWalker-v2/) is a robotic task in OpenAI Gym since it performs one of the most fundamental skills: moving. In this task, our goal is to get a 2D bipedal walker to walk through rough terrain. BipedalWalker is a difficult task in continuous action space, and there are only a few RL implementations can reach the target reward."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "DbamGVHC3AeW"
            },
            "source": [
                "# **Part 1: Install ElegantRL**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "U35bhkUqOqbS",
                "outputId": "79ace170-9a20-46cd-db96-957fd42a472f"
            },
            "outputs": [],
            "source": [
                "# install elegantrl library\n",
                "!pip install git+https://github.com/AI4Finance-LLC/ElegantRL.git"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "UVdmpnK_3Zcn"
            },
            "source": [
                "# **Part 2: Import Packages**\n",
                "\n",
                "\n",
                "*   **elegantrl**\n",
                "*   **OpenAI Gym**: a toolkit for developing and comparing reinforcement learning algorithms.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "id": "AAPdjovQrTpE"
            },
            "outputs": [],
            "source": [
                "import gym\n",
                "from elegantrl.agents import AgentPPO\n",
                "from elegantrl.train.config import get_gym_env_args, Arguments\n",
                "from elegantrl.train.run import *\n",
                "\n",
                "gym.logger.set_level(40) # Block warning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "z2Ik5cDoyPGU"
            },
            "source": [
                "# **Part 3: Get environment information**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "wwkZXiHtyV6f",
                "outputId": "880d25f5-d1f0-4cd2-8f78-bb5409330101"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[33;1m⚠ [WARNING]\u001b[0m \u001b[33mWARNING: env.action_space.high: \u001b[0m [1. 1. 1. 1.]\n",
                        "\u001b[34;1m⚑ [INFO]\u001b[0m \u001b[34menv_args:\u001b[0m\n",
                        "{\n",
                        "    'env_num': 1,\n",
                        "    'env_name': 'BipedalWalker-v3',\n",
                        "    'max_step': 1600,\n",
                        "    'state_dim': 24,\n",
                        "    'action_dim': 4,\n",
                        "    'if_discrete': False,\n",
                        "    'target_return': 300,\n",
                        "}\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'env_num': 1,\n",
                            " 'env_name': 'BipedalWalker-v3',\n",
                            " 'max_step': 1600,\n",
                            " 'state_dim': 24,\n",
                            " 'action_dim': 4,\n",
                            " 'if_discrete': False,\n",
                            " 'target_return': 300}"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_gym_env_args(gym.make(\"BipedalWalker-v3\"), if_print=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "3n8zcgcn14uq"
            },
            "source": [
                "# **Part 4: Specify Agent and Environment**\n",
                "\n",
                "*   **agent**: chooses a agent (DRL algorithm) from a set of agents in the [directory](https://github.com/AI4Finance-Foundation/ElegantRL/tree/master/elegantrl/agents).\n",
                "*   **env_func**: the function to create an environment, in this case, we use gym.make to create BipedalWalker-v3.\n",
                "*   **env_args**: the environment information.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "E03f6cTeajK4"
            },
            "outputs": [],
            "source": [
                "env_func = gym.make\n",
                "env_args = {\n",
                "    \"env_num\": 1,\n",
                "    \"env_name\": \"BipedalWalker-v3\",\n",
                "    \"max_step\": 1600,\n",
                "    \"state_dim\": 24,\n",
                "    \"action_dim\": 4,\n",
                "    \"if_discrete\": False,\n",
                "    \"target_return\": 300,\n",
                "    \"id\": \"BipedalWalker-v3\",\n",
                "}\n",
                "\n",
                "env = gym.make(\"BipedalWalker-v3\")\n",
                "args = Arguments(AgentPPO, env=env, env_func=env_func, env_args=env_args)\n",
                "\n",
                "# args = Arguments(AgentPPO, env_func=env_func, env_args=env_args)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rcFcUkwfzHLE"
            },
            "source": [
                "# **Part 4: Specify hyper-parameters**\n",
                "A list of hyper-parameters is available [here](https://elegantrl.readthedocs.io/en/latest/api/config.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "9WCAcmIfzGyE"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "6400\n"
                    ]
                }
            ],
            "source": [
                "args.target_step = args.max_step * 4\n",
                "args.gamma = 0.98\n",
                "args.eval_times = 2**4\n",
                "args.repeat_times = 8"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "z1j5kLHF2dhJ"
            },
            "source": [
                "# **Part 5: Train and Evaluate the Agent**\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "KGOPSD6da23k",
                "outputId": "2a8ed03b-b306-45f8-c530-adf72438c5bd"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34;1m⚑ [INFO]\u001b[0m \u001b[34m<Arguments.init_before_training> setting cwd...\u001b[0m\n",
                        "\u001b[32;1m✔ [SUCCESS]\u001b[0m \u001b[32mcwd set in:\u001b[0m\n",
                        "/Users/jimmy/Projects/RL/ElegantRL/ElegantRL-fork/experiments/BipedalWalker-v3_PPO_0\n",
                        "\u001b[33;1m⚠ [WARNING]\u001b[0m \u001b[33m<Arguments> Remove cwd:\u001b[0m\n",
                        "/Users/jimmy/Projects/RL/ElegantRL/ElegantRL-fork/experiments/BipedalWalker-v3_PPO_0\n",
                        "\u001b[34;1m⚑ [INFO]\u001b[0m \u001b[34m<run.py/init_agent> initializing agent...\u001b[0m\n",
                        "\u001b[34;1m⚑ [INFO]\u001b[0m \u001b[34minitializing buffer...\u001b[0m\n",
                        "\u001b[34;1m⚑ [INFO]\u001b[0m \u001b[34minitializing evaluator...\u001b[0m\n",
                        "\u001b[35;1m➤ [DEBUG]\u001b[0m \u001b[35m<run.py/init_evaluator> building env...\u001b[0m\n",
                        "\u001b[35;1m➤ [DEBUG]\u001b[0m \u001b[35m<config.py/builing_env> building env...\u001b[0m\n",
                        "\u001b[33;1m⚠ [WARNING]\u001b[0m \u001b[33menv is not None, deepcopy...\u001b[0m\n",
                        "\u001b[35;1m➤ [DEBUG]\u001b[0m \u001b[35msetattr for env...\u001b[0m\n",
                        "\u001b[32;1m✔ [SUCCESS]\u001b[0m \u001b[32menv built:\u001b[0m <TimeLimit<BipedalWalker instance>>\n",
                        "################################################################################\n",
                        "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n",
                        "\u001b[33;1m⚠ [WARNING]\u001b[0m \u001b[33menv is not None\u001b[0m\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "cat() received an invalid combination of arguments - got (map, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/Users/jimmy/Projects/RL/ElegantRL/ElegantRL-fork/tutorial_BipedalWalker_v3.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jimmy/Projects/RL/ElegantRL/ElegantRL-fork/tutorial_BipedalWalker_v3.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_and_evaluate(args)\n",
                        "File \u001b[0;32m~/Projects/RL/ElegantRL/ElegantRL-fork/elegantrl/train/run.py:121\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mwhile\u001b[39;00m if_train:\n\u001b[1;32m    120\u001b[0m     trajectory \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mexplore_env(env, horizon_len)\n\u001b[0;32m--> 121\u001b[0m     steps, r_exp \u001b[39m=\u001b[39m buffer\u001b[39m.\u001b[39;49mupdate_buffer((trajectory,))\n\u001b[1;32m    122\u001b[0m     \u001b[39mif\u001b[39;00m if_off_policy:\n\u001b[1;32m    123\u001b[0m         buffer\u001b[39m.\u001b[39mupdate_buffer(trajectory)\n",
                        "File \u001b[0;32m~/Projects/RL/ElegantRL/ElegantRL-fork/elegantrl/train/replay_buffer.py:315\u001b[0m, in \u001b[0;36mReplayBufferList.update_buffer\u001b[0;34m(self, traj_list)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_buffer\u001b[39m(\u001b[39mself\u001b[39m, traj_list):\n\u001b[1;32m    314\u001b[0m     cur_items \u001b[39m=\u001b[39m [\u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mtraj_list))]\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mself\u001b[39m[:] \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mcat(item, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m cur_items]\n\u001b[1;32m    317\u001b[0m     steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    318\u001b[0m     r_exp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n",
                        "File \u001b[0;32m~/Projects/RL/ElegantRL/ElegantRL-fork/elegantrl/train/replay_buffer.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_buffer\u001b[39m(\u001b[39mself\u001b[39m, traj_list):\n\u001b[1;32m    314\u001b[0m     cur_items \u001b[39m=\u001b[39m [\u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mtraj_list))]\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mself\u001b[39m[:] \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39;49mcat(item, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m cur_items]\n\u001b[1;32m    317\u001b[0m     steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    318\u001b[0m     r_exp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n",
                        "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (map, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
                    ]
                }
            ],
            "source": [
                "train_and_evaluate(args)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "JPXOxLSqh5cP"
            },
            "source": [
                "Understanding the above results::\n",
                "*   **Step**: the total training steps.\n",
                "*  **MaxR**: the maximum reward.\n",
                "*   **avgR**: the average of the rewards.\n",
                "*   **stdR**: the standard deviation of the rewards.\n",
                "*   **objA**: the objective function value of Actor Network (Policy Network).\n",
                "*   **objC**: the objective function value (Q-value)  of Critic Network (Value Network)."
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "include_colab_link": true,
            "name": "tutorial_BipedalWalker-v3.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.9.12",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "vscode": {
            "interpreter": {
                "hash": "93ba34249c17563af2bda868fdb6eca5c87de58ecf012fca691323eb0b85f674"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
